{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking parameters...\n",
      "Parameter check complete. Executing Duplicate Detection\n",
      "Number of bands:  3\n",
      "Number of rows per band:  64\n",
      "Sigma:  2.0\n",
      "Selected features:  ('duration', 'end_of_fade_in', 'key', 'loudness', 'mode', 'start_of_fade_out', 'tempo', 'time_signature')\n",
      "Distance:  0.0006091729809042379\n",
      "Extracting the tarfile...\n",
      "Extracting the summary...\n",
      "Extracting the features...\n",
      "Real time elapsed for extract fields:  21.269211053848267\n",
      "number of Random Vectors :  192\n",
      "Time taken to generate Random Vectors:  0.0\n",
      "Index:  1\n",
      "Candidate pairs on  1  band:  2699\n",
      "Index:  2\n",
      "Candidate pairs on  2  band:  3330\n",
      "Index:  3\n",
      "Candidate pairs on  3  band:  3132\n",
      "Found:  22  duplicates\n",
      "Time taken to find duplicates:  0.5050048828125\n",
      "Time taken to find duplicates with generation of random vectors and preprocessing of the data:  3.0850319862365723\n",
      "Exiting the program\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import display\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import scale\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import itertools as it\n",
    "\n",
    "band = widgets.IntSlider(\n",
    "    value=3,\n",
    "    min=1,\n",
    "    max=8,\n",
    "    step=1,\n",
    "    description='Number of Band',\n",
    ")\n",
    "\n",
    "row = widgets.IntSlider(\n",
    "    value=64,\n",
    "    min=20,\n",
    "    max=128,\n",
    "    step=1,\n",
    "    description='Number of row in a band',\n",
    ")\n",
    "\n",
    "sigma_v = widgets.FloatSlider(\n",
    "    value=2.0,\n",
    "    min=1.0,\n",
    "    max=10.0,\n",
    "    step=0.5,\n",
    "    description='Value of sigma',\n",
    ")\n",
    "\n",
    "feature_list = widgets.SelectMultiple(\n",
    "    description=\"Feature List\",\n",
    "    value=('duration', 'end_of_fade_in', 'key', 'loudness', 'mode', 'start_of_fade_out', 'tempo', 'time_signature'),\n",
    "    options=['analysis_sample_rate', 'audio_md5', 'danceability', 'duration', 'end_of_fade_in', 'energy', 'idx_bars_confidence', 'idx_bars_start', 'idx_beats_confidence', 'idx_beats_start', 'idx_sections_confidence', 'idx_sections_start', 'idx_segments_confidence', 'idx_segments_loudness_max', 'idx_segments_loudness_max_time', 'idx_segments_loudness_start', 'idx_segments_pitches', 'idx_segments_start', 'idx_segments_timbre', 'idx_tatums_confidence', 'idx_tatums_start', 'key',  'key_confidence', 'loudness', 'mode', 'mode_confidence', 'start_of_fade_out', 'tempo', 'time_signature', 'time_signature_confidence', 'track_id']\n",
    ")\n",
    "\n",
    "display(band)\n",
    "display(row)\n",
    "display(sigma_v)\n",
    "display(feature_list)\n",
    "\n",
    "button = widgets.Button(description=\"Execute!\")\n",
    "display(button)\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    clear_output()\n",
    "    print(\"Checking parameters...\")\n",
    "    if not feature_list.value:\n",
    "        print(\"Feature list cannont be empty. Please recheck.\")\n",
    "        print(\"Program Exiting...\")\n",
    "    else:\n",
    "        print(\"Parameter check complete. Executing Duplicate Detection\")\n",
    "        main_func_backend(band.value, row.value, sigma_v.value, feature_list.value)\n",
    "\n",
    "button.on_click(on_button_clicked)\n",
    "# ****************************************************************************************** #\n",
    "path_to_million_song_dataset = \"G:\\\\MS\\\\TUM\\\\courses\\\\Mining Massive Datasets\\\\millionsongsubset_full.tar.gz\"\n",
    "\n",
    "hash_vector = np.array([2**i for i in range(64)])\n",
    "\n",
    "duplicate_songs = dict()\n",
    "\n",
    "#\n",
    "#   Returns a matrix which columns corresponds to a specific feature:\n",
    "#   Each row corresponds to a song\n",
    "#   Each field a for the moment floats\n",
    "#\n",
    "#   features:A list containing features\n",
    "#   dataframe: frame containing all feature data\n",
    "#   n: number of songs\n",
    "#\n",
    "#   returns: Numpy.Matrix(col=feature,row=songs)\n",
    "#\n",
    "def extract_fields(features, dataframe, n):\n",
    "    number_of_features = len(features)\n",
    "    feature_data_matrix = np.empty((n, number_of_features))\n",
    "    for i in range(n):\n",
    "        col_index = 0\n",
    "        for feature in features:\n",
    "            feature_data_matrix[i][col_index] = dataframe.iloc[i][feature]\n",
    "            col_index += 1\n",
    "\n",
    "    feature_data_matrix = scale(feature_data_matrix)\n",
    "    return feature_data_matrix\n",
    "#\n",
    "#   Generates a \"random\" matrix\n",
    "#\n",
    "def generate_random_v(rows, cols):\n",
    "    v = np.random.choice([-1,1], (rows, cols))\n",
    "    return v\n",
    "    \n",
    "def banding(signature_matrix, num_bands, rows_in_band, num_RV, sigma):\n",
    "    band_start_index = 0\n",
    "    band_end_index = rows_in_band - 1 \n",
    "    index = 0\n",
    "   \n",
    "    while(band_end_index <= num_RV):\n",
    "        \n",
    "        #print(\"starting index: \",  band_start_index, \" and band end index: \", band_end_index)\n",
    "        #print(\"sigma \", sigma)\n",
    "        index += 1\n",
    "        #print(\"Index: \", index)\n",
    "        band = signature_matrix[band_start_index:band_end_index+1]\n",
    "        hashing(band, sigma, index)\n",
    "        band_start_index = band_end_index + 1\n",
    "        band_end_index += rows_in_band\n",
    "\n",
    "    duplicates = 0\n",
    "    for song,similiarity_list in duplicate_songs.items():\n",
    "        if len(similiarity_list) > 0:\n",
    "            duplicates += (len(similiarity_list))\n",
    "            #print(\"Duplicate pairs: \", song, \" and \", similiarity_list)\n",
    "\n",
    "    print(\"Found: \", duplicates, \" duplicates\")\n",
    "\n",
    "def hashing(band, sigma, index):\n",
    "    candidate_pairs = 0\n",
    " \n",
    "    hash_buckets = dict()\n",
    "    \n",
    "    for j in range(band.shape[1]):\n",
    "        local_song_signature = band[:, j]\n",
    "        hash_value = getHashValue(local_song_signature)\n",
    "        if hash_value not in hash_buckets: \n",
    "            hash_buckets[hash_value] = [j]\n",
    "        else:\n",
    "            hash_buckets[hash_value].append(j) \n",
    "    \n",
    "    for bucket in hash_buckets.items():\n",
    "        if len(bucket[1]) > 1:\n",
    "            candidate_pairs += len(bucket[1])\n",
    "        \n",
    "    find_exact_cosine_distance(hash_buckets, sigma)\n",
    "\n",
    "    print(\"Candidate pairs on \", index  , \" band: \", candidate_pairs)\n",
    "\n",
    "def find_exact_cosine_distance(hash_buckets, sigma):\n",
    "    global feature_data_matrix\n",
    "\n",
    "    for bucket in hash_buckets.items():\n",
    "        for (i,j) in it.combinations(bucket[1], 2):\n",
    "\n",
    "            if i not in duplicate_songs:\n",
    "                duplicate_songs[i] = set([])\n",
    "             \n",
    "            if j not in duplicate_songs[i]:\n",
    "                cosine_value = cosine_similarity(feature_data_matrix[i], feature_data_matrix[j]) \n",
    "                if cosine_value < sigma:\n",
    "                    duplicate_songs[i].update([j])\n",
    "\n",
    "def cosine_similarity(song1, song2):\n",
    "    mag1 = np.linalg.norm(song1)\n",
    "    mag2 = np.linalg.norm(song2)\n",
    "\n",
    "    cos_angle = np.dot(song1, song2)/(mag1*mag2)\n",
    "\n",
    "    return 1 - cos_angle\n",
    "\n",
    "def getHashValue(local_song_signature):\n",
    "    hashValue = 0\n",
    "    \n",
    "    #   print(\"local song signature shape after transpose: \", local_song_signature.shape)\n",
    "    hashValue = np.dot(local_song_signature, hash_vector)\n",
    "    return hashValue\n",
    "        \n",
    "def find_duplicates(feature_data_matrix, r, b, sigma):\n",
    "    dimensions = feature_data_matrix.shape\n",
    "\n",
    "    time1 = time.time()\n",
    "    num_of_RV = r*b\n",
    "    print(\"number of Random Vectors : \", num_of_RV)\n",
    "    v = generate_random_v(num_of_RV, dimensions[1])\n",
    "    time2 = time.time()\n",
    "    print(\"Time taken to generate Random Vectors: \", time2-time1)\n",
    " \n",
    "    #print(\"Rank of matrix: \", np.linalg.matrix_rank(v))\n",
    "    \n",
    "    v = v.transpose()\n",
    "    \n",
    "    signature_matrix = np.dot(feature_data_matrix, v)\n",
    "    \n",
    "    for i in range(signature_matrix.shape[0]):\n",
    "        for j in range(signature_matrix.shape[1]):\n",
    "            if signature_matrix[i][j] > 0:\n",
    "                signature_matrix[i][j] = 1\n",
    "            else:\n",
    "                signature_matrix[i][j] = 0\n",
    "    \n",
    "    time1 = time.time()\n",
    "    banding(signature_matrix.transpose(), b, r, num_of_RV, sigma)\n",
    "    time2 = time.time()\n",
    "    print(\"Time taken to find duplicates: \", time2 - time1)\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def main_func_backend(num_band, num_row, sigma, feature_list):\n",
    "    global feature_data_matrix\n",
    "    print(\"Number of bands: \", num_band)\n",
    "    print(\"Number of rows per band: \", num_row)\n",
    "    print(\"Sigma: \", sigma)\n",
    "    print(\"Selected features: \", feature_list)\n",
    "    distance =  1 - math.cos(math.radians(sigma))\n",
    "    print(\"Distance: \", distance)\n",
    "    \n",
    "    print(\"Extracting the tarfile...\")\n",
    "    t = tarfile.open(path_to_million_song_dataset, \"r:gz\")\n",
    "    members = t.getmembers()\n",
    "\n",
    "    print(\"Extracting the summary...\")\n",
    "    t.extract(members[5].name)\n",
    "    summary = pd.HDFStore(members[5].name)\n",
    "\n",
    "    print(\"Extracting the features...\")\n",
    "    time1 = time.time()\n",
    "    feature_data_matrix = extract_fields(feature_list, summary['analysis/songs'], 9999)\n",
    "    \n",
    "\n",
    "    time2 = time.time()\n",
    "    print(\"Real time elapsed for extract fields: \", time2-time1)\n",
    "\n",
    "    time1 = time.time()\n",
    "\n",
    "    find_duplicates(feature_data_matrix, num_row, num_band, distance)\n",
    "    time2 = time.time()\n",
    "\n",
    "    print(\"Time taken to find duplicates with generation of random vectors and preprocessing of the data: \", time2-time1)\n",
    "    print(\"Exiting the program\")\n",
    "    t.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "0b7899c9663146d6bb87a495a8898207": {
     "views": [
      {
       "cell_index": 0
      }
     ]
    },
    "17fc8b4aac1a403a804e39bf485cf0bf": {
     "views": [
      {
       "cell_index": 0
      }
     ]
    },
    "1ac8fb21b78f4a0b92d101add2cbf044": {
     "views": [
      {
       "cell_index": 0
      }
     ]
    },
    "37c9386a42ff4581bdc8a508e8943c5b": {
     "views": [
      {
       "cell_index": 0
      }
     ]
    },
    "5490235ca6934c688ab9ce577827ef6a": {
     "views": [
      {
       "cell_index": 0
      }
     ]
    },
    "59fda08c52cc449f96a46b94f0929408": {
     "views": [
      {
       "cell_index": 0
      }
     ]
    },
    "7b24620958a044b7b545a32d20b1d698": {
     "views": [
      {
       "cell_index": 0
      }
     ]
    },
    "80e30555e67940bdb291a6c0b298eabe": {
     "views": [
      {
       "cell_index": 0
      }
     ]
    },
    "89ae407e5a9b4b0a863359826971f6fb": {
     "views": [
      {
       "cell_index": 0
      }
     ]
    },
    "955d8f1eed804d3fb540cfda920f9647": {
     "views": [
      {
       "cell_index": 0
      }
     ]
    },
    "a0023125cd764c87a322684b5eb8e2a0": {
     "views": [
      {
       "cell_index": 0
      }
     ]
    },
    "acea5421773e48b682dce64e7351d2d8": {
     "views": [
      {
       "cell_index": 0
      }
     ]
    },
    "bfce8c21bbca4f6dbc60948efd8f6906": {
     "views": [
      {
       "cell_index": 0
      }
     ]
    },
    "c4fe10ffc58f423d9d9b7cc0b4980ad3": {
     "views": [
      {
       "cell_index": 0
      }
     ]
    },
    "d3ad8ac29c2741088ca953b340d35a3d": {
     "views": [
      {
       "cell_index": 0
      }
     ]
    },
    "d5e7aea29daa40afab023f496b4c122a": {
     "views": [
      {
       "cell_index": 0
      }
     ]
    },
    "e9f174fc40424188bdc440bb75485ecf": {
     "views": [
      {
       "cell_index": 0
      }
     ]
    },
    "f542d43d80ec4d52880e0129b8deb82f": {
     "views": [
      {
       "cell_index": 0
      }
     ]
    },
    "fa202b058207412986025f08e9c0a969": {
     "views": [
      {
       "cell_index": 0
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
