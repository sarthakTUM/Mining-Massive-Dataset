{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Song Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code does the following:-\n",
    "1. Parse the input text \f",
    "le and create the user-song matrix M.\n",
    "2. Preprocess the data by binning the play counts into b bins.\n",
    "3. Preprocess the data to avoid the cold start issue, and getting the final shape as (5693; 10966)\n",
    "4. set-aside 200 randomly selected non-zero data-points from the matrix as a test set.\n",
    "\n",
    "TODO:-\n",
    "This code does note perform Alternating Optimization using Ridge Regression as of now. We are trying our best to incorporate the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing the triplets...\n",
      "Highest playcount:  1890\n",
      "Bin Array :  [1, 2, 4, 8, 16, 32, 64, 128, 256, 512]\n",
      "Binned Counts :  [1 1 2 ..., 1 1 1]\n",
      "Done parsing the triplets -> Sparse matrix\n",
      "Intermediate shape:  (6270, 11212)\n",
      "Intermediate shape:  (5716, 10981)\n",
      "Intermediate shape:  (5695, 10966)\n",
      "Intermediate shape:  (5693, 10966)\n",
      "Intermediate shape:  (5693, 10966)\n",
      "Picking random test set: \n",
      "Matrix shape :  (5693, 10966)\n",
      "U shape :  (5693, 6)  sigma shape :  (6,)  V shape :  (6, 10966)\n",
      "Sigma shape after converting to diagonal matrix :  (6, 6)\n",
      "Q shape :  (5693, 6)\n",
      "Pt shape :  (6, 10966)\n",
      "Shape of Qt :  (6, 5693)\n",
      "Orig shape:  (300000, 300000)  Final shape:  (5693, 10966)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import scipy.sparse.linalg as spl\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "file_path = \"G:\\\\MS\\\\TUM\\\\courses\\\\Mining Massive Datasets\\\\project\\\\train_triplets.txt\\\\train_triplets.txt\"\n",
    "# The sparse matrix function\n",
    "def create_sparse_matrix(users, songs, play_count, row=True):\n",
    "    if row:\n",
    "        return sp.csr_matrix((play_count, (users, songs)), shape=(len(users), len(songs)))\n",
    "    else:\n",
    "        return sp.csc_matrix((play_count, (users, songs)), shape=(len(users), len(songs)))\n",
    "\n",
    "# The parse triplets function\n",
    "def parse_triplets(file_path, max_rows, whole_dataset, b, use_vectors, use_dikt):\n",
    "    # Vectors\n",
    "\n",
    "    users = []\n",
    "    songs = []\n",
    "    play_count = []\n",
    "\n",
    "    mapping_users = {}\n",
    "    mapping_songs = {}\n",
    "    \n",
    "    # Code to extract users, songs and playcount from the train_triplets.txt \n",
    "\n",
    "    triplets = open(file_path, 'r')\n",
    "    \n",
    "    line_regex = re.compile(\"^([\\w\\d]+)\\t([\\w\\d]+)\\t([\\w]+)$\")\n",
    "\n",
    "    current_row = 0\n",
    "\n",
    "    highest_playcount = 0\n",
    "\n",
    "    for triplet in triplets:\n",
    "        triplet_match = line_regex.match(triplet)\n",
    "\n",
    "        if (use_vectors):\n",
    "            if triplet_match.group(1) not in mapping_users:\n",
    "                mapping_users[triplet_match.group(1)] = len(mapping_users)\n",
    "    \n",
    "            if triplet_match.group(2) not in mapping_songs:\n",
    "                mapping_songs[triplet_match.group(2)] = len(mapping_songs)\n",
    "\n",
    "            users.append(int(mapping_users[triplet_match.group(1)]))\n",
    "            songs.append(int(mapping_songs[triplet_match.group(2)]))\n",
    "            play_count.append(int(triplet_match.group(3)))\n",
    "\n",
    "        if int(triplet_match.group(3)) > highest_playcount:\n",
    "            highest_playcount = int(triplet_match.group(3))\n",
    "\n",
    "        current_row += 1\n",
    "        if current_row >= max_rows and not whole_dataset:\n",
    "            break\n",
    "\n",
    "    triplets.close()\n",
    "\n",
    "    print(\"Highest playcount: \", highest_playcount)\n",
    "\n",
    "    return (users, songs, play_count)\n",
    "\n",
    "    \n",
    "def binning(play_count, bin_size):\n",
    "    bin_array = [2**i for i in range(bin_size)]\n",
    "    print(\"Bin Array : \", bin_array)\n",
    "    binned_counts = np.digitize(play_count, bin_array, right = False)\n",
    "    print(\"Binned Counts : \", binned_counts)\n",
    "    return binned_counts\n",
    "        \n",
    "    \n",
    "def cold_start(user_song_matrix, min_threshold):\n",
    "    #We need to remove songs & users with less or equal to min_threshold \n",
    "    #print(user_song_matrix)\n",
    "    user_song_matrix = user_song_matrix > 0\n",
    "    user_song_matrix = user_song_matrix.astype(np.int)\n",
    "    #print(user_song_matrix.toarray())\n",
    "        \n",
    "    songs_per_user = np.ravel(np.sum(user_song_matrix, axis=1)) #sum of row\n",
    "    users_to_delete = np.where(songs_per_user <= min_threshold)[0]\n",
    "    \n",
    "    ##set the users i.e rows to 0\n",
    "    for i in users_to_delete:\n",
    "            user_song_matrix.data[user_song_matrix.indptr[i]:user_song_matrix.indptr[i+1]]=0\n",
    "\n",
    "    user_song_matrix.eliminate_zeros()\n",
    "    mask = np.concatenate(([True], user_song_matrix.indptr[1:] != user_song_matrix.indptr[:-1]))\n",
    "    user_song_matrix = sp.csr_matrix((user_song_matrix.data, user_song_matrix.indices, user_song_matrix.indptr[mask]))\n",
    "\n",
    "    ##set the songs i.e columns to 0\n",
    "    user_song_matrix = sp.csc_matrix(user_song_matrix)\n",
    "    \n",
    "    users_per_song = np.ravel(np.sum(user_song_matrix, axis=0)) #sum of column\n",
    "    songs_to_delete = np.where(users_per_song <= min_threshold)[0]\n",
    "\n",
    "    for i in songs_to_delete:\n",
    "            user_song_matrix.data[user_song_matrix.indptr[i]:user_song_matrix.indptr[i+1]]=0\n",
    "\n",
    "    user_song_matrix.eliminate_zeros()\n",
    "    mask = np.concatenate(([True], user_song_matrix.indptr[1:] != user_song_matrix.indptr[:-1]))\n",
    "    user_song_matrix = sp.csc_matrix((user_song_matrix.data, user_song_matrix.indices, user_song_matrix.indptr[mask]))\t\n",
    "    \n",
    "    return user_song_matrix.tocsr()\n",
    "\n",
    "def singular_value_decomp(sparse_matrix):\n",
    "    sparse_matrix = sparse_matrix.asfptype()\n",
    "    print(\"Matrix shape : \", sparse_matrix.shape)\n",
    "    # print(\"Sparse Matrix : \", sparse_matrix)\n",
    "    \n",
    "    U, sigma, Vt = spl.svds(sparse_matrix)\n",
    "    print(\"U shape : \", U.shape, \" sigma shape : \", sigma.shape, \" V shape : \", Vt.shape)\n",
    "    \n",
    "    sigma = np.diag(sigma)\n",
    "    print(\"Sigma shape after converting to diagonal matrix : \", sigma.shape)\n",
    "    Q = U.dot(sigma)\n",
    "    print(\"Q shape : \", Q.shape)\n",
    "    print(\"Pt shape : \", Vt.shape)\n",
    "    return Q, Vt\n",
    "\n",
    "def Alternating_optimization(Q,Pt, user_song_matrix):\n",
    "\n",
    "    dot_sum = 0\n",
    "    Qt = np.transpose(Q)\n",
    "#==============================================================================\n",
    "#     row_vector= Q[0, :]\n",
    "#     column_vector = Q[:, 0]\n",
    "#     print(column_vector.shape[0])\n",
    "# \n",
    "#     print(\"Row vector : \", row_vector)\n",
    "#     print(\"Col Vector : \", column_vector)\n",
    "#     \n",
    "#==============================================================================\n",
    "\n",
    "    print(\"Shape of Qt : \", Qt.shape)\n",
    "    #print(\"Q : \", Q, \" and Qt : \", Qt)\n",
    "\n",
    "# have to impletement Minimize function\n",
    "#==============================================================================\n",
    "#     Q = minimize(Q, Pt, 0, dot_sum)\n",
    "#     Pt = minimize(Q, Pt, 1, dot_sum)\n",
    "#==============================================================================\n",
    "\n",
    "#\n",
    "#   This functions picks a random set of size: number_of_random_elements\n",
    "#   \n",
    "#   Returns: M_s the modified M\n",
    "#            random_set containing all random pciked elements on the form [(row,col,data)]\n",
    "#\n",
    "def pick_random_test_set(M, number_of_random_elements):\n",
    "    random.seed(time.time())\n",
    "    \n",
    "    M_s = sp.coo_matrix(M)\n",
    "    interval = len(M_s.data)\n",
    "\n",
    "    random_picked_values = []\n",
    "    already_picked_values = []\n",
    "    \n",
    "    for i in range(number_of_random_elements):\n",
    "        random_index = random.randint(0, interval-1)\n",
    "\n",
    "        while random_index in already_picked_values:\n",
    "            random_index = random.randint(0, interval-1)\n",
    "        already_picked_values.append(random_index)\n",
    "        \n",
    "        random_picked_values.append((M_s.row[random_index], \n",
    "                                    M_s.col[random_index], \n",
    "                                    M_s.data[random_index]))\n",
    "        M_s.data[random_index] = 0\n",
    "        #print(random_picked_values[len(random_picked_values)-1])\n",
    "\n",
    "    M_s.eliminate_zeros()\n",
    "    M_s = sp.csr_matrix(M_s)\n",
    "    return M_s, random_picked_values\n",
    "    \n",
    "if len(sys.argv) < 2:\n",
    "    print(\"To few arguments...\")\n",
    "    sys.exit(1)\n",
    "\n",
    "min_threshold = 5\n",
    "bin_size = 10 ## This is configurable by user\n",
    "size_of_test_set = 200\n",
    "\n",
    "print(\"Parsing the triplets...\")\n",
    "users, songs, play_count = parse_triplets(file_path, 300000, False, 10, True, False)\n",
    "\n",
    "# Here the logic for the binnig should be placed\n",
    "\n",
    "binned_play_counts = binning(play_count, bin_size)\n",
    "\n",
    "# Either pass this binned_play_counts to the following functions that require play_count\n",
    "# as a parameter, or change the return variable \"binned_play_counts\" to \"play_count\"\n",
    "# to override its value\n",
    "\n",
    "# Easiest way to create a sparse matrix is done by using the vectors\n",
    "resulting_sparse_matrix = create_sparse_matrix(users, songs, binned_play_counts, row=True)\n",
    "print(\"Done parsing the triplets -> Sparse matrix\")\n",
    "\n",
    "shape_orig = resulting_sparse_matrix.shape\n",
    "while True:\n",
    "    shape_before = resulting_sparse_matrix.shape\n",
    "    resulting_sparse_matrix = cold_start(resulting_sparse_matrix, min_threshold)\n",
    "    shape_after = resulting_sparse_matrix.shape\n",
    "    print(\"Intermediate shape: \", shape_after)\n",
    "    if shape_before[0] == shape_after[0] and shape_before[1] == shape_after[1]:\n",
    "        break\n",
    "shape_final = resulting_sparse_matrix.shape\n",
    "\n",
    "print(\"Picking random test set: \")\n",
    "resulting_sparse_matrix, test_set = pick_random_test_set(resulting_sparse_matrix, size_of_test_set)\n",
    "\n",
    "#print(\"Got random test set: \", test_set)\n",
    "\n",
    "# Initial P & Q values obtained using SVD\n",
    "Q, Pt = singular_value_decomp(resulting_sparse_matrix)\n",
    "# Perform AO using P,Q\n",
    "Alternating_optimization(Q,Pt, resulting_sparse_matrix)\n",
    "\n",
    "print(\"Orig shape: \", shape_orig, \" Final shape: \", shape_after)\n",
    "sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
