{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SONG RECOMMENDATION - PART 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. debugging batch gradient descent. loss is decreasing though.\n",
    "2. debugging stochastic gradient descent. loss is decreasing though.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing the triplets...\n",
      "Highest playcount:  1890\n",
      "Bin Array :  [1, 2, 4, 8, 16, 32, 64, 128, 256, 512]\n",
      "Binned Counts :  [1 1 2 ..., 1 1 1]\n",
      "Done parsing the triplets -> Sparse matrix\n",
      "Intermediate shape:  (6270, 11212)\n",
      "Intermediate shape:  (5716, 10981)\n",
      "Intermediate shape:  (5695, 10966)\n",
      "Intermediate shape:  (5693, 10966)\n",
      "Intermediate shape:  (5693, 10966)\n",
      "Picking random test set: \n",
      "Matrix shape :  (5693, 10966)\n",
      "U shape :  (5693, 30)  sigma shape :  (30,)  V shape :  (30, 10966)\n",
      "Sigma shape after converting to diagonal matrix :  (30, 30)\n",
      "Q shape :  (5693, 30)\n",
      "Pt shape :  (30, 10966)\n",
      "Running batch gd\n",
      "M size (5693, 10966)\n",
      "initial Q size (5693, 30)\n",
      "initial Pt size (30, 10966)\n",
      "num of element in M 171025\n",
      "P shape index 30 10966\n",
      "loss1 3.75390935606\n",
      "shape gradient (30, 10966)\n",
      "loss2 3.75388892797\n",
      "shape gradient (30, 10966)\n",
      "loss2 3.7538685237\n",
      "shape gradient (30, 10966)\n",
      "loss2 3.75384821731\n",
      "shape gradient (30, 10966)\n",
      "loss2 3.75382887073\n",
      "shape gradient (30, 10966)\n",
      "loss2 3.75381947493\n",
      "shape gradient (30, 10966)\n",
      "loss2 3.75391354654\n",
      "Running stoc gd\n",
      "M size (5693, 10966)\n",
      "initial Q size (5693, 30)\n",
      "initial Pt size (30, 10966)\n",
      "num of element in M 171025\n",
      "P shape index 30 10966\n",
      "loss1 3.75390935606\n",
      "random_x :  5116\n",
      "random_i :  7769\n",
      "random_r :  0\n",
      "loss2 3.75390935559\n",
      "random_x :  4488\n",
      "random_i :  1558\n",
      "random_r :  0\n",
      "loss2 3.75390935533\n",
      "random_x :  4757\n",
      "random_i :  9706\n",
      "random_r :  0\n",
      "loss2 3.75390935533\n",
      "random_x :  1535\n",
      "random_i :  3950\n",
      "random_r :  0\n",
      "loss2 3.75390935532\n",
      "random_x :  41\n",
      "random_i :  7594\n",
      "random_r :  0\n",
      "loss2 3.7539093553\n",
      "random_x :  2251\n",
      "random_i :  2679\n",
      "random_r :  0\n",
      "loss2 3.75390935389\n",
      "random_x :  2258\n",
      "random_i :  2263\n",
      "random_r :  0\n",
      "loss2 3.75390935373\n",
      "random_x :  5515\n",
      "random_i :  1332\n",
      "random_r :  0\n",
      "loss2 3.75390935331\n",
      "random_x :  1684\n",
      "random_i :  10649\n",
      "random_r :  0\n",
      "loss2 3.7539093519\n",
      "random_x :  4119\n",
      "random_i :  8381\n",
      "random_r :  0\n",
      "loss2 3.75390935027\n",
      "Orig shape:  (300000, 300000)  Final shape:  (5693, 10966)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import scipy.sparse.linalg as spl\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "from scipy import sparse\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "filepath=\"train_triplets.txt\"\n",
    "\n",
    "# The sparse matrix function\n",
    "def create_sparse_matrix(users, songs, play_count, row=True):\n",
    "    if row:\n",
    "        return sp.csr_matrix((play_count, (users, songs)), shape=(len(users), len(songs)))\n",
    "    else:\n",
    "        return sp.csc_matrix((play_count, (users, songs)), shape=(len(users), len(songs)))\n",
    "\n",
    "# The parse triplets function\n",
    "def parse_triplets(file_path, max_rows, whole_dataset, b, use_vectors, use_dikt):\n",
    "    # Vectors\n",
    "\n",
    "    users = []\n",
    "    songs = []\n",
    "    play_count = []\n",
    "\n",
    "    mapping_users = {}\n",
    "    mapping_songs = {}\n",
    "    \n",
    "    # Code to extract users, songs and playcount from the train_triplets.txt \n",
    "\n",
    "    triplets = open(file_path, 'r')\n",
    "    \n",
    "    line_regex = re.compile(\"^([\\w\\d]+)\\t([\\w\\d]+)\\t([\\w]+)$\")\n",
    "\n",
    "    current_row = 0\n",
    "\n",
    "    highest_playcount = 0\n",
    "\n",
    "    for triplet in triplets:\n",
    "        triplet_match = line_regex.match(triplet)\n",
    "\n",
    "        if (use_vectors):\n",
    "            if triplet_match.group(1) not in mapping_users:\n",
    "                mapping_users[triplet_match.group(1)] = len(mapping_users)\n",
    "    \n",
    "            if triplet_match.group(2) not in mapping_songs:\n",
    "                mapping_songs[triplet_match.group(2)] = len(mapping_songs)\n",
    "\n",
    "            users.append(int(mapping_users[triplet_match.group(1)]))\n",
    "            songs.append(int(mapping_songs[triplet_match.group(2)]))\n",
    "            play_count.append(int(triplet_match.group(3)))\n",
    "\n",
    "        if int(triplet_match.group(3)) > highest_playcount:\n",
    "            highest_playcount = int(triplet_match.group(3))\n",
    "\n",
    "        current_row += 1\n",
    "        if current_row >= max_rows and not whole_dataset:\n",
    "            break\n",
    "\n",
    "    triplets.close()\n",
    "\n",
    "    print(\"Highest playcount: \", highest_playcount)\n",
    "\n",
    "    return (users, songs, play_count)\n",
    "\n",
    "    \n",
    "def binning(play_count, bin_size):\n",
    "    bin_array = [2**i for i in range(bin_size)]\n",
    "    print(\"Bin Array : \", bin_array)\n",
    "    binned_counts = np.digitize(play_count, bin_array, right = False)\n",
    "    print(\"Binned Counts : \", binned_counts)\n",
    "    return binned_counts\n",
    "        \n",
    "    \n",
    "def cold_start(user_song_matrix, min_threshold):\n",
    "    #We need to remove songs & users with less or equal to min_threshold \n",
    "    #print(user_song_matrix)\n",
    "    #user_song_matrix = user_song_matrix > 0\n",
    "    user_song_matrix = user_song_matrix.astype(np.int)\n",
    "    #print(user_song_matrix.toarray())\n",
    " \n",
    "    songs_per_user = np.ravel(np.sum((user_song_matrix > 0), axis=1)) #sum of row\n",
    "    users_to_delete = np.where(songs_per_user <= min_threshold)[0]\n",
    "    \n",
    "    ##set the users i.e rows to 0\n",
    "    for i in users_to_delete:\n",
    "            user_song_matrix.data[user_song_matrix.indptr[i]:user_song_matrix.indptr[i+1]]=0\n",
    "\n",
    "    user_song_matrix.eliminate_zeros()\n",
    "    mask = np.concatenate(([True], user_song_matrix.indptr[1:] != user_song_matrix.indptr[:-1]))\n",
    "    user_song_matrix = sp.csr_matrix((user_song_matrix.data, user_song_matrix.indices, user_song_matrix.indptr[mask]))\n",
    "\n",
    "    ##set the songs i.e columns to 0\n",
    "    user_song_matrix = sp.csc_matrix(user_song_matrix)\n",
    "    \n",
    "    users_per_song = np.ravel(np.sum((user_song_matrix > 0), axis=0)) #sum of column\n",
    "    songs_to_delete = np.where(users_per_song <= min_threshold)[0]\n",
    "\n",
    "    for i in songs_to_delete:\n",
    "            user_song_matrix.data[user_song_matrix.indptr[i]:user_song_matrix.indptr[i+1]]=0\n",
    "\n",
    "    user_song_matrix.eliminate_zeros()\n",
    "    mask = np.concatenate(([True], user_song_matrix.indptr[1:] != user_song_matrix.indptr[:-1]))\n",
    "    user_song_matrix = sp.csc_matrix((user_song_matrix.data, user_song_matrix.indices, user_song_matrix.indptr[mask]))\t\n",
    "    \n",
    "    return user_song_matrix.tocsr()\n",
    "\n",
    "def singular_value_decomp(sparse_matrix):\n",
    "    sparse_matrix = sparse_matrix.asfptype()\n",
    "    print(\"Matrix shape : \", sparse_matrix.shape)\n",
    "    # print(\"Sparse Matrix : \", sparse_matrix)\n",
    "    \n",
    "    U, sigma, Vt = spl.svds(sparse_matrix, k=30)\n",
    "    print(\"U shape : \", U.shape, \" sigma shape : \", sigma.shape, \" V shape : \", Vt.shape)\n",
    "    \n",
    "    sigma = np.diag(sigma)\n",
    "    print(\"Sigma shape after converting to diagonal matrix : \", sigma.shape)\n",
    "    Q = U.dot(sigma)\n",
    "    print(\"Q shape : \", Q.shape)\n",
    "    print(\"Pt shape : \", Vt.shape)\n",
    "    return Q, Vt\n",
    "\n",
    "#\n",
    "#   This functions picks a random set of size: number_of_random_elements\n",
    "#   \n",
    "#   Returns: M_s the modified M\n",
    "#            random_set containing all random pciked elements on the form [(row,col,data)]\n",
    "#\n",
    "def pick_random_test_set(M, number_of_random_elements):\n",
    "    random.seed(time.time())\n",
    "    \n",
    "    M_s = sp.coo_matrix(M)\n",
    "    interval = len(M_s.data)\n",
    "\n",
    "    random_picked_values = []\n",
    "    already_picked_values = []\n",
    "    \n",
    "    for i in range(number_of_random_elements):\n",
    "        random_index = random.randint(0, interval-1)\n",
    "\n",
    "        while random_index in already_picked_values:\n",
    "            random_index = random.randint(0, interval-1)\n",
    "        already_picked_values.append(random_index)\n",
    "        \n",
    "        random_picked_values.append((M_s.row[random_index], \n",
    "                                    M_s.col[random_index], \n",
    "                                    M_s.data[random_index]))\n",
    "        M_s.data[random_index] = 0\n",
    "\n",
    "    M_s.eliminate_zeros()\n",
    "    M_s = sp.csr_matrix(M_s)\n",
    "    return M_s, random_picked_values\n",
    "\n",
    "#M is in csr format\n",
    "def calc_loss(M, Q, Pt):\n",
    "\t#TODO we have to optimize it\n",
    "    lamda1 = 0.3;lamda2 = 0.3\n",
    "\n",
    "    loss = ((M - Q.dot(Pt)).power(2)).sum()\n",
    "    loss += lamda1*(np.sum(np.square(spl.norm(Pt, axis=0)))) + lamda2*(np.sum(np.square(spl.norm(Q, axis=1))))\n",
    "    loss = loss/171072\n",
    "    return loss\n",
    "\n",
    "#M is in csr format\n",
    "def gradient_loss_P(M, Q, Pt):\n",
    "\tlamda1 = 0.3\n",
    "\n",
    "\t#print(\"shape Q\", Q.shape, \"Pt\", Pt.shape)\n",
    "\tgradient = ((-2 * (M - Q.dot(Pt))).transpose()).dot(Q)\n",
    "\tgradient = gradient.transpose()\n",
    "\tprint(\"shape gradient\", gradient.shape)\n",
    "\tgradient += (2*lamda1*Pt)\n",
    "\t#gradient = gradient.transpose()\n",
    "    #print(\"shape gradient after 2lamda1\", gradient.shape)\n",
    "\t#print(gradient)\n",
    "\treturn gradient\n",
    "\n",
    "# M is in csr format\n",
    "def gradient_loss_Q(M, Q, Pt):\n",
    "\tlamda2 = 0.3\n",
    "\n",
    "\t#print(\"shape Q\", Q.shape, \"Pt\", Pt.shape)\n",
    "\tgradient = ((-2 * (M - Q.dot(Pt)))).dot(Pt.transpose())\n",
    "\tgradient += (2*lamda2*Q)\n",
    "\t#print(\"shape gradient after 2lamda1\", gradient.shape)\n",
    "\treturn gradient\n",
    "\n",
    "def gradient_descent(M, Pt, Q):\n",
    "    lr_rate = 0.0001\n",
    "    print(\"M size\", M.shape)\n",
    "    print(\"initial Q size\", Q.shape)\n",
    "    print(\"initial Pt size\", Pt.shape)\n",
    "    print(\"num of element in M\", len(M.data))\n",
    "    print(\"P shape index\", Pt.shape[0], Pt.shape[1])\n",
    "\n",
    "    Q = sp.csr_matrix(Q)\n",
    "    Pt = sp.csr_matrix(Pt)\n",
    "\n",
    "    loss1 = calc_loss(M, Q, Pt)\n",
    "    print(\"loss1\", loss1)\n",
    "\n",
    "    #print(M-Q.dot(Pt))\n",
    "    for iter in range(6):\n",
    "       temp0 = Pt - (lr_rate * gradient_loss_P(M, Q, Pt))\n",
    "       temp1 = Q - (lr_rate * gradient_loss_Q(M, Q, Pt))\n",
    "       Pt = temp0\n",
    "       Q = temp1\n",
    "       #print(\"sum of Pt & Q\")\n",
    "       #print(Pt.sum(), Q.sum())\n",
    "       #print(\"final Q size\", Q.shape)\n",
    "       #print(\"final Pt size\", Pt.shape)\n",
    "       loss2 = calc_loss(M, Q, Pt)\n",
    "       print(\"loss2\", loss2)\n",
    "    return None\n",
    "#----------------------------------------------------\n",
    "#M is in csr format\n",
    "def calc_loss_stoc(M, Q, Pt):\n",
    "\t#TODO we have to optimize it\n",
    "    lamda1 = 0.3;lamda2 = 0.3\n",
    "\n",
    "    \n",
    "    loss = (((M - Q.dot(Pt)).power(2)).sum())\n",
    "    loss += lamda1*(np.sum(np.square(spl.norm(Pt, axis=0)))) + lamda2*(np.sum(np.square(spl.norm(Q, axis=1))))\n",
    "    loss = loss/171072\n",
    "    \n",
    "    return loss\n",
    "\n",
    "#M is in csr format\n",
    "def gradient_loss_Px_stoc(r, qx, pi):\n",
    "\tlamda1 = 0.5\n",
    "\n",
    "\tgradient = (-2 * (r - (qx.dot(pi)[0,0]))) * qx\n",
    "\tgradient += 2*lamda1*pi.transpose()\n",
    "     \n",
    "\tgradient = gradient.transpose()\n",
    "\t#print(\"shape gradientPx\", gradient.shape)\n",
    "\t#gradient += (2*lamda1*Pt)\n",
    "\t#print(\"shape gradient after 2lamda1\", gradient.shape)\n",
    "\t#print(gradient)\n",
    "\treturn gradient\n",
    "\n",
    "# M is in csr format\n",
    "def gradient_loss_Qi_stoc(r, qx, pi):\n",
    "\tlamda2 = 0.5\n",
    "\n",
    "\tgradient = (-2 * (r - (qx.dot(pi)[0,0]))) * pi\n",
    "\tgradient += 2*lamda2*qx.transpose()\n",
    "\tgradient = gradient.transpose()\n",
    "\t#print(\"shape gradientQi\", gradient.shape)\n",
    "\t#gradient += (2*lamda2*Q)\n",
    "\t#print(\"shape gradient after 2lamda1\", gradient.shape)\n",
    "\treturn gradient\n",
    "\n",
    "def gradient_descent_stoc(M, Pt, Q):\n",
    "    lr_rate = 0.0001\n",
    "    print(\"M size\", M.shape)\n",
    "    print(\"initial Q size\", Q.shape)\n",
    "    print(\"initial Pt size\", Pt.shape)\n",
    "    print(\"num of element in M\", len(M.data))\n",
    "    print(\"P shape index\", Pt.shape[0], Pt.shape[1])\n",
    "\n",
    "    Q = sp.csr_matrix(Q)\n",
    "    Pt = sp.csr_matrix(Pt)\n",
    "\n",
    "    \n",
    "    loss1 = calc_loss_stoc(M, Q, Pt)\n",
    "    print(\"loss1\", loss1)\n",
    "    \n",
    "\n",
    "    #print(M-Q.dot(Pt))\n",
    "    #M = M.tocoo();\n",
    "    \n",
    "    for iter in range(10):\n",
    "        \n",
    "        #r=M.data[d]; x=M.row[d]; i=M.col[d];\n",
    "        random_x = random.randint(0, M.shape[0])\n",
    "        print(\"random_x : \", random_x)\n",
    "        \n",
    "        random_i = random.randint(0, M.shape[1])\n",
    "        print(\"random_i : \", random_i)\n",
    "        \n",
    "        random_r = M[random_x, random_i]\n",
    "        print(\"random_r : \", random_r)\n",
    "    \n",
    "\n",
    "        temp0 = Pt[:,random_i] - (lr_rate * gradient_loss_Px_stoc(random_r, Q[random_x,:], Pt[:,random_i]))\n",
    "        #print(Pt[:, random_i].dtype)\n",
    "        temp1 = Q[random_x,:] - (lr_rate * gradient_loss_Qi_stoc(random_r, Q[random_x,:], Pt[:,random_i]))\n",
    "      \n",
    "        Pt[:,random_i] = temp0\n",
    "        Q[random_x,:] = temp1\n",
    "\n",
    "        loss2 = calc_loss_stoc(M, Q, Pt)\n",
    "        print(\"loss2\", loss2)\n",
    "    M=M.tocsr()\n",
    "    return None\n",
    "#----------------------------------------------------\n",
    "\n",
    "def finding_method(M, Q, P):\n",
    "    P = sp.csr_matrix(P_stoc)\n",
    "    Q = sp.csr_matrix(Q)\n",
    "    M = sp.csr_matrix(M)\n",
    "\n",
    "    print(\"P sh:\", P.shape)\n",
    "    print(\"Q sh:\", Q.shape)\n",
    "        \n",
    "    m_shape = M.shape\n",
    "    \n",
    "    print(type(M[0,:]))\n",
    "\n",
    "    print(\"Q.T shape: \", Q.T.shape)\n",
    "    print(\"Q shape: \", Q.shape)\n",
    "    #print(np.einsum('ji,j->ji', Q, Q))\n",
    "\n",
    "    qTq = np.sum(np.dot(Q.T,Q).diagonal())\n",
    "    print(\"qTq: \", qTq)\n",
    "    #print(qTq.shape)\n",
    "\n",
    "    pTp = np.sum(np.dot(P.T, P).diagonal())\n",
    "    print(\"pTp: \", pTp)\n",
    "    \n",
    "    for x in range(m_shape[1]):\n",
    "        m = M[:,x]\n",
    "        #print(\"Q.T shape: \", Q.T.shape)\n",
    "        #print(\"m.T shape: \",  m.T.shape)\n",
    "\n",
    "        #print(\"Q shape: \", Q.shape)\n",
    "        #print(\"m shape: \",  m.shape)\n",
    "        p_x = (1/pTp) * np.dot(Q.T, m)\n",
    "        \n",
    "        #print(\"P shape first : \", P.shape)\n",
    "        P = sp.vstack((sp.vstack((P[:x], p_x.T)), P[x+1:]))\n",
    "        #print(\"P shape after : \", P.shape)\n",
    "        #print(P.data[P.indptr[x]:P.indptr[x+1]])\n",
    "\n",
    "        #print(\"p_x: \", p_x.shape)\n",
    "\n",
    "    print(\"Done with P\")\n",
    "\n",
    "    for i in range(m_shape[0]):\n",
    "        m = M[i,:]\n",
    "        q_i = (1/qTq) * np.dot(P.T, m.T)\n",
    "\n",
    "        Q = sp.vstack((sp.vstack((Q[:i], q_i.T)), Q[i+1:]))\n",
    "\n",
    "    print(np.dot(Q,P.T).shape)\n",
    "\n",
    "    np.sum(np.norm('l2', M - np.dot(Q,P.T)), axis=1)\n",
    "    #print(m.shape)\n",
    "    #print(l.shape)\n",
    "    print(\"Done\")\n",
    "    \n",
    "def rmse(Mdiff, test_set):\n",
    "    \n",
    "    y_sum = 0\n",
    "    for test in test_set:\n",
    "        y_sum += (test[2] - Mdiff[test[0]][test[1]])**2\n",
    "\n",
    "    rmse = np.sqrt(y_sum/len(test_set))\n",
    "\n",
    "    print(\"RMSE: \", rmse)\n",
    "\n",
    "if len(sys.argv) < 2:\n",
    "    print(\"To few arguments...\")\n",
    "    sys.exit(1)\n",
    "\n",
    "min_threshold = 5\n",
    "bin_size = 10 ## This is configurable by user\n",
    "size_of_test_set = 200\n",
    "\n",
    "print(\"Parsing the triplets...\")\n",
    "users, songs, play_count = parse_triplets(filepath, 300000, False, 10, True, False)\n",
    "\n",
    "# Here the logic for the binnig should be placed\n",
    "\n",
    "binned_play_counts = binning(play_count, bin_size)\n",
    "\n",
    "# Either pass this binned_play_counts to the following functions that require play_count\n",
    "# as a parameter, or change the return variable \"binned_play_counts\" to \"play_count\"\n",
    "# to override its value\n",
    "\n",
    "# Easiest way to create a sparse matrix is done by using the vectors\n",
    "resulting_sparse_matrix = create_sparse_matrix(users, songs, binned_play_counts, row=True)\n",
    "print(\"Done parsing the triplets -> Sparse matrix\")\n",
    "\n",
    "shape_orig = resulting_sparse_matrix.shape\n",
    "while True:\n",
    "    shape_before = resulting_sparse_matrix.shape\n",
    "    resulting_sparse_matrix = cold_start(resulting_sparse_matrix, min_threshold)\n",
    "    shape_after = resulting_sparse_matrix.shape\n",
    "    print(\"Intermediate shape: \", shape_after)\n",
    "    if shape_before[0] == shape_after[0] and shape_before[1] == shape_after[1]:\n",
    "        break\n",
    "shape_final = resulting_sparse_matrix.shape\n",
    "\n",
    "print(\"Picking random test set: \")\n",
    "resulting_sparse_matrix, test_set = pick_random_test_set(resulting_sparse_matrix, size_of_test_set)\n",
    "\n",
    "#print(\"Got random test set: \", test_set)\n",
    "\n",
    "# Initial P & Q values obtained using SVD\n",
    "Q, Pt = singular_value_decomp(resulting_sparse_matrix)\n",
    "\n",
    "# Perform AO using P,Q\n",
    "Pt_orig = Pt\n",
    "Q_orig = Q\n",
    "print(\"Running batch gd\");\n",
    "gradient_descent(resulting_sparse_matrix, Pt, Q)\n",
    "print(\"Running stoc gd\");\n",
    "gradient_descent_stoc(resulting_sparse_matrix, Pt_orig, Q_orig)\n",
    "\n",
    "\n",
    "\n",
    "#find_method(resulting_sparse_matrix, Q, Pt.T)\n",
    "print(\"Orig shape: \", shape_orig, \" Final shape: \", shape_after)\n",
    "sys.stdout.flush()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
